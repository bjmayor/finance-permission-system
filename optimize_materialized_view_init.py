#!/usr/bin/env python3
"""
ç‰©åŒ–è§†å›¾åˆå§‹åŒ–æ€§èƒ½ä¼˜åŒ–è„šæœ¬

å½“å‰é—®é¢˜åˆ†æï¼š
1. å•ä¸€å¤§æŸ¥è¯¢ï¼š1ç™¾ä¸‡æ¡è´¢åŠ¡è®°å½• Ã— 5åƒä¸ªsupervisor = å¯èƒ½äº§ç”Ÿæ•°åäº¿æ¬¡JOINè®¡ç®—
2. æ— æ‰¹é‡å¤„ç†ï¼šä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰æ•°æ®å¯¼è‡´å†…å­˜å’Œé”ç«äº‰
3. æ— å¹¶è¡ŒåŒ–ï¼šä¸²è¡Œæ‰§è¡Œæ‰€æœ‰supervisorçš„æ•°æ®ç”Ÿæˆ
4. ç´¢å¼•å†²çªï¼šå¤§é‡INSERTæ—¶ç´¢å¼•ç»´æŠ¤å¼€é”€å·¨å¤§

ä¼˜åŒ–ç­–ç•¥ï¼š
1. åˆ†æ‰¹å¤„ç†ï¼šå°†supervisoråˆ†ç»„ï¼Œæ¯æ‰¹å¤„ç†å°‘é‡supervisor
2. å¹¶è¡Œä¼˜åŒ–ï¼šåˆ©ç”¨MySQLçš„æ‰¹é‡æ’å…¥å’Œä¼˜åŒ–é…ç½®
3. ä¸´æ—¶ç¦ç”¨ç´¢å¼•ï¼šåœ¨æ•°æ®æ’å…¥æœŸé—´ç¦ç”¨éå¿…è¦ç´¢å¼•
4. å¢é‡æ›´æ–°ï¼šæ”¯æŒåªæ›´æ–°ç‰¹å®šsupervisorçš„æ•°æ®
5. å†…å­˜ä¼˜åŒ–ï¼šè°ƒæ•´MySQLé…ç½®ä»¥æ”¯æŒå¤§æ‰¹é‡æ“ä½œ
"""

import os
import time
import argparse
import mysql.connector
from dotenv import load_dotenv
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from prettytable import PrettyTable

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# æ•°æ®åº“è¿æ¥é…ç½®
config = {
    'host': os.getenv('DB_HOST_V2', '127.0.0.1'),
    'port': int(os.getenv('DB_PORT_V2', '3306')),
    'user': os.getenv('DB_USER_V2', 'root'),
    'password': os.getenv('DB_PASSWORD_V2', '123456'),
    'database': os.getenv('DB_NAME_V2', 'finance'),
    'autocommit': False,  # æ‰‹åŠ¨æ§åˆ¶äº‹åŠ¡
    'charset': 'utf8mb4'
}

# çº¿ç¨‹é”
print_lock = threading.Lock()
stats_lock = threading.Lock()

def safe_print(*args, **kwargs):
    """çº¿ç¨‹å®‰å…¨çš„æ‰“å°"""
    with print_lock:
        print(*args, **kwargs)

def connect_db():
    """è¿æ¥æ•°æ®åº“"""
    try:
        conn = mysql.connector.connect(**config)
        return conn
    except mysql.connector.Error as e:
        safe_print(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        return None

def optimize_mysql_settings():
    """ä¼˜åŒ–MySQLè®¾ç½®ä»¥æé«˜æ‰¹é‡æ’å…¥æ€§èƒ½"""
    conn = connect_db()
    if not conn:
        return False
    
    cursor = conn.cursor()
    
    try:
        safe_print("=== ä¼˜åŒ–MySQLè®¾ç½® ===")
        
        # è·å–å½“å‰è®¾ç½®
        cursor.execute("SHOW VARIABLES LIKE 'innodb_buffer_pool_size'")
        buffer_pool = cursor.fetchone()
        
        cursor.execute("SHOW VARIABLES LIKE 'bulk_insert_buffer_size'")
        bulk_insert = cursor.fetchone()
        
        safe_print(f"å½“å‰InnoDBç¼“å†²æ± å¤§å°: {buffer_pool[1] if buffer_pool else 'unknown'}")
        safe_print(f"å½“å‰æ‰¹é‡æ’å…¥ç¼“å†²åŒº: {bulk_insert[1] if bulk_insert else 'unknown'}")
        
        # è®¾ç½®ä¼šè¯çº§åˆ«çš„ä¼˜åŒ–å‚æ•°
        optimizations = [
            "SET SESSION bulk_insert_buffer_size = 256*1024*1024",  # 256MB
            "SET SESSION innodb_change_buffering = all",
            "SET SESSION foreign_key_checks = 0",  # ä¸´æ—¶ç¦ç”¨å¤–é”®æ£€æŸ¥
            "SET SESSION unique_checks = 0",       # ä¸´æ—¶ç¦ç”¨å”¯ä¸€æ€§æ£€æŸ¥
            "SET SESSION sql_log_bin = 0"          # ç¦ç”¨äºŒè¿›åˆ¶æ—¥å¿—ï¼ˆå¦‚æœä¸éœ€è¦å¤åˆ¶ï¼‰
        ]
        
        for opt in optimizations:
            try:
                cursor.execute(opt)
                safe_print(f"âœ… {opt}")
            except mysql.connector.Error as e:
                safe_print(f"âš ï¸ {opt} - {e}")
        
        conn.commit()
        safe_print("MySQLä¼˜åŒ–è®¾ç½®å®Œæˆ")
        return True
        
    except mysql.connector.Error as e:
        safe_print(f"âŒ MySQLä¼˜åŒ–å¤±è´¥: {e}")
        return False
    finally:
        cursor.close()
        conn.close()

def backup_and_recreate_mv_table():
    """å¤‡ä»½å¹¶é‡å»ºç‰©åŒ–è§†å›¾è¡¨ï¼Œä¼˜åŒ–ç»“æ„"""
    conn = connect_db()
    if not conn:
        return False
    
    cursor = conn.cursor()
    
    try:
        safe_print("\n=== é‡å»ºç‰©åŒ–è§†å›¾è¡¨ç»“æ„ ===")
        
        # å¤‡ä»½ç°æœ‰è¡¨ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        cursor.execute("SHOW TABLES LIKE 'mv_supervisor_financial'")
        if cursor.fetchone():
            safe_print("å¤‡ä»½ç°æœ‰ç‰©åŒ–è§†å›¾è¡¨...")
            cursor.execute("DROP TABLE IF EXISTS mv_supervisor_financial_backup")
            cursor.execute("RENAME TABLE mv_supervisor_financial TO mv_supervisor_financial_backup")
        
        # åˆ›å»ºä¼˜åŒ–åçš„è¡¨ç»“æ„
        safe_print("åˆ›å»ºä¼˜åŒ–çš„è¡¨ç»“æ„...")
        cursor.execute("""
            CREATE TABLE mv_supervisor_financial (
                id BIGINT AUTO_INCREMENT,
                supervisor_id INT NOT NULL,
                fund_id INT NOT NULL,
                handle_by INT NOT NULL,
                handler_name VARCHAR(255),
                department VARCHAR(100),
                order_id INT,
                customer_id INT,
                amount DECIMAL(15, 2),
                last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                PRIMARY KEY (id)
            ) ENGINE=InnoDB 
              DEFAULT CHARSET=utf8mb4 
              ROW_FORMAT=COMPRESSED
              KEY_BLOCK_SIZE=8
        """)
        
        # æ³¨æ„ï¼šæš‚æ—¶ä¸åˆ›å»ºå…¶ä»–ç´¢å¼•ï¼Œåœ¨æ•°æ®æ’å…¥å®Œæˆåå†æ·»åŠ 
        
        conn.commit()
        safe_print("âœ… è¡¨ç»“æ„åˆ›å»ºå®Œæˆï¼ˆç´¢å¼•å°†åœ¨æ•°æ®æ’å…¥ååˆ›å»ºï¼‰")
        return True
        
    except mysql.connector.Error as e:
        safe_print(f"âŒ è¡¨ç»“æ„åˆ›å»ºå¤±è´¥: {e}")
        conn.rollback()
        return False
    finally:
        cursor.close()
        conn.close()

def get_supervisor_batches(batch_size=100):
    """è·å–supervisoræ‰¹æ¬¡åˆ—è¡¨"""
    conn = connect_db()
    if not conn:
        return []
    
    cursor = conn.cursor()
    
    try:
        # è·å–æ‰€æœ‰æœ‰ä¸‹å±çš„supervisorï¼Œå¹¶æŒ‰ä¸‹å±æ•°é‡æ’åº
        cursor.execute("""
            SELECT h.user_id, COUNT(*) as subordinate_count
            FROM user_hierarchy h
            GROUP BY h.user_id
            ORDER BY subordinate_count DESC
        """)
        
        supervisors = cursor.fetchall()
        
        # åˆ†æ‰¹ï¼Œæ¯æ‰¹åŒ…å«batch_sizeä¸ªsupervisor
        batches = []
        for i in range(0, len(supervisors), batch_size):
            batch = supervisors[i:i + batch_size]
            batch_subordinates = sum(count for _, count in batch)
            batches.append({
                'batch_id': i // batch_size + 1,
                'supervisors': [sup_id for sup_id, _ in batch],
                'supervisor_count': len(batch),
                'estimated_records': batch_subordinates  # ä¼°ç®—è®°å½•æ•°
            })
        
        return batches
        
    except mysql.connector.Error as e:
        safe_print(f"âŒ è·å–supervisoræ‰¹æ¬¡å¤±è´¥: {e}")
        return []
    finally:
        cursor.close()
        conn.close()

def process_supervisor_batch(batch_info, total_batches):
    """å¤„ç†å•ä¸ªsupervisoræ‰¹æ¬¡"""
    conn = connect_db()
    if not conn:
        return {'success': False, 'error': 'Database connection failed'}
    
    cursor = conn.cursor()
    
    try:
        batch_id = batch_info['batch_id']
        supervisors = batch_info['supervisors']
        estimated_records = batch_info['estimated_records']
        
        safe_print(f"å¼€å§‹å¤„ç†æ‰¹æ¬¡ {batch_id}/{total_batches}ï¼š{len(supervisors)} ä¸ªsupervisorï¼Œé¢„ä¼° {estimated_records:,} æ¡è®°å½•")
        
        start_time = time.time()
        
        # æ„å»ºæ‰¹é‡æ’å…¥æŸ¥è¯¢
        placeholders = ','.join(['%s'] * len(supervisors))
        
        insert_query = f"""
            INSERT INTO mv_supervisor_financial 
                (supervisor_id, fund_id, handle_by, handler_name, department, order_id, customer_id, amount)
            SELECT 
                h.user_id AS supervisor_id,
                f.fund_id,
                f.handle_by,
                u.name AS handler_name,
                u.department,
                f.order_id,
                f.customer_id,
                f.amount
            FROM user_hierarchy h
            JOIN financial_funds f ON h.subordinate_id = f.handle_by
            JOIN users u ON f.handle_by = u.id
            WHERE h.user_id IN ({placeholders})
        """
        
        cursor.execute(insert_query, supervisors)
        inserted_count = cursor.rowcount
        
        conn.commit()
        
        elapsed_time = time.time() - start_time
        
        result = {
            'success': True,
            'batch_id': batch_id,
            'supervisor_count': len(supervisors),
            'inserted_count': inserted_count,
            'elapsed_time': elapsed_time,
            'records_per_second': inserted_count / elapsed_time if elapsed_time > 0 else 0
        }
        
        safe_print(f"âœ… æ‰¹æ¬¡ {batch_id} å®Œæˆï¼šæ’å…¥ {inserted_count:,} æ¡è®°å½•ï¼Œè€—æ—¶ {elapsed_time:.2f}sï¼Œé€Ÿåº¦ {result['records_per_second']:.0f} è®°å½•/ç§’")
        
        return result
        
    except mysql.connector.Error as e:
        safe_print(f"âŒ æ‰¹æ¬¡ {batch_info['batch_id']} å¤±è´¥: {e}")
        conn.rollback()
        return {'success': False, 'batch_id': batch_info['batch_id'], 'error': str(e)}
    finally:
        cursor.close()
        conn.close()

def parallel_populate_materialized_view(max_workers=4, batch_size=100):
    """å¹¶è¡Œå¡«å……ç‰©åŒ–è§†å›¾"""
    safe_print("\n=== å¹¶è¡Œå¡«å……ç‰©åŒ–è§†å›¾ ===")
    
    # è·å–æ‰¹æ¬¡
    batches = get_supervisor_batches(batch_size)
    if not batches:
        safe_print("âŒ æ— æ³•è·å–supervisoræ‰¹æ¬¡")
        return False
    
    total_batches = len(batches)
    total_supervisors = sum(b['supervisor_count'] for b in batches)
    estimated_total_records = sum(b['estimated_records'] for b in batches)
    
    safe_print(f"æ€»å…± {total_batches} ä¸ªæ‰¹æ¬¡ï¼Œ{total_supervisors} ä¸ªsupervisorï¼Œé¢„ä¼° {estimated_total_records:,} æ¡è®°å½•")
    safe_print(f"ä½¿ç”¨ {max_workers} ä¸ªå¹¶è¡Œçº¿ç¨‹")
    
    overall_start_time = time.time()
    results = []
    
    # å¹¶è¡Œå¤„ç†æ‰¹æ¬¡
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_batch = {
            executor.submit(process_supervisor_batch, batch, total_batches): batch
            for batch in batches
        }
        
        # å¤„ç†å®Œæˆçš„ä»»åŠ¡
        for future in as_completed(future_to_batch):
            result = future.result()
            results.append(result)
    
    overall_elapsed_time = time.time() - overall_start_time
    
    # ç»Ÿè®¡ç»“æœ
    successful_batches = [r for r in results if r['success']]
    failed_batches = [r for r in results if not r['success']]
    
    total_inserted = sum(r.get('inserted_count', 0) for r in successful_batches)
    average_speed = sum(r.get('records_per_second', 0) for r in successful_batches) / len(successful_batches) if successful_batches else 0
    
    safe_print(f"\n=== å¹¶è¡Œå¡«å……å®Œæˆ ===")
    safe_print(f"æ€»è€—æ—¶: {overall_elapsed_time:.2f} ç§’")
    safe_print(f"æˆåŠŸæ‰¹æ¬¡: {len(successful_batches)}/{total_batches}")
    safe_print(f"å¤±è´¥æ‰¹æ¬¡: {len(failed_batches)}")
    safe_print(f"æ€»æ’å…¥è®°å½•: {total_inserted:,}")
    safe_print(f"å¹³å‡é€Ÿåº¦: {average_speed:.0f} è®°å½•/ç§’")
    safe_print(f"æ•´ä½“é€Ÿåº¦: {total_inserted / overall_elapsed_time:.0f} è®°å½•/ç§’")
    
    if failed_batches:
        safe_print(f"\nå¤±è´¥çš„æ‰¹æ¬¡:")
        for failed in failed_batches:
            safe_print(f"  æ‰¹æ¬¡ {failed.get('batch_id', 'unknown')}: {failed.get('error', 'unknown error')}")
    
    return len(failed_batches) == 0

def create_indexes_after_data_load():
    """åœ¨æ•°æ®åŠ è½½å®Œæˆååˆ›å»ºç´¢å¼•"""
    conn = connect_db()
    if not conn:
        return False
    
    cursor = conn.cursor()
    
    try:
        safe_print("\n=== åˆ›å»ºç´¢å¼• ===")
        
        indexes = [
            "ALTER TABLE mv_supervisor_financial ADD INDEX idx_supervisor_id (supervisor_id)",
            "ALTER TABLE mv_supervisor_financial ADD INDEX idx_supervisor_fund (supervisor_id, fund_id)",
            "ALTER TABLE mv_supervisor_financial ADD INDEX idx_supervisor_amount (supervisor_id, amount)",
            "ALTER TABLE mv_supervisor_financial ADD INDEX idx_fund_id (fund_id)",
            "ALTER TABLE mv_supervisor_financial ADD INDEX idx_last_updated (last_updated)"
        ]
        
        for i, index_sql in enumerate(indexes, 1):
            safe_print(f"åˆ›å»ºç´¢å¼• {i}/{len(indexes)}...")
            start_time = time.time()
            
            cursor.execute(index_sql)
            
            elapsed = time.time() - start_time
            safe_print(f"  âœ… å®Œæˆï¼Œè€—æ—¶ {elapsed:.2f}s")
        
        conn.commit()
        safe_print("âœ… æ‰€æœ‰ç´¢å¼•åˆ›å»ºå®Œæˆ")
        return True
        
    except mysql.connector.Error as e:
        safe_print(f"âŒ ç´¢å¼•åˆ›å»ºå¤±è´¥: {e}")
        conn.rollback()
        return False
    finally:
        cursor.close()
        conn.close()

def restore_mysql_settings():
    """æ¢å¤MySQLè®¾ç½®"""
    conn = connect_db()
    if not conn:
        return False
    
    cursor = conn.cursor()
    
    try:
        safe_print("\n=== æ¢å¤MySQLè®¾ç½® ===")
        
        restorations = [
            "SET SESSION foreign_key_checks = 1",
            "SET SESSION unique_checks = 1",
            "SET SESSION sql_log_bin = 1"
        ]
        
        for restore in restorations:
            try:
                cursor.execute(restore)
                safe_print(f"âœ… {restore}")
            except mysql.connector.Error as e:
                safe_print(f"âš ï¸ {restore} - {e}")
        
        conn.commit()
        safe_print("MySQLè®¾ç½®æ¢å¤å®Œæˆ")
        return True
        
    except mysql.connector.Error as e:
        safe_print(f"âŒ MySQLè®¾ç½®æ¢å¤å¤±è´¥: {e}")
        return False
    finally:
        cursor.close()
        conn.close()

def update_timestamps():
    """æ›´æ–°æ—¶é—´æˆ³"""
    conn = connect_db()
    if not conn:
        return False
    
    cursor = conn.cursor()
    
    try:
        safe_print("\næ›´æ–°æ—¶é—´æˆ³...")
        cursor.execute("UPDATE mv_supervisor_financial SET last_updated = NOW()")
        conn.commit()
        safe_print(f"âœ… å·²æ›´æ–° {cursor.rowcount:,} æ¡è®°å½•çš„æ—¶é—´æˆ³")
        return True
        
    except mysql.connector.Error as e:
        safe_print(f"âŒ æ—¶é—´æˆ³æ›´æ–°å¤±è´¥: {e}")
        return False
    finally:
        cursor.close()
        conn.close()

def verify_materialized_view():
    """éªŒè¯ç‰©åŒ–è§†å›¾"""
    conn = connect_db()
    if not conn:
        return False
    
    cursor = conn.cursor()
    
    try:
        safe_print("\n=== éªŒè¯ç‰©åŒ–è§†å›¾ ===")
        
        # åŸºæœ¬ç»Ÿè®¡
        cursor.execute("SELECT COUNT(*) FROM mv_supervisor_financial")
        total_records = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(DISTINCT supervisor_id) FROM mv_supervisor_financial")
        unique_supervisors = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(DISTINCT fund_id) FROM mv_supervisor_financial")
        unique_funds = cursor.fetchone()[0]
        
        safe_print(f"æ€»è®°å½•æ•°: {total_records:,}")
        safe_print(f"ä¸åŒsupervisoræ•°: {unique_supervisors:,}")
        safe_print(f"ä¸åŒfundæ•°: {unique_funds:,}")
        
        # æŠ½æ ·éªŒè¯
        cursor.execute("""
            SELECT supervisor_id, COUNT(*) as record_count
            FROM mv_supervisor_financial
            GROUP BY supervisor_id
            ORDER BY record_count DESC
            LIMIT 5
        """)
        
        top_supervisors = cursor.fetchall()
        safe_print("\nè®°å½•æœ€å¤šçš„5ä¸ªsupervisor:")
        for sup_id, count in top_supervisors:
            safe_print(f"  Supervisor {sup_id}: {count:,} æ¡è®°å½•")
        
        # æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥ï¼ˆæŠ½æ ·ï¼‰
        test_supervisor = top_supervisors[0][0] if top_supervisors else None
        if test_supervisor:
            safe_print(f"\nå¯¹supervisor {test_supervisor}è¿›è¡Œä¸€è‡´æ€§æ£€æŸ¥...")
            
            # ç‰©åŒ–è§†å›¾è®°å½•æ•°
            cursor.execute("SELECT COUNT(*) FROM mv_supervisor_financial WHERE supervisor_id = %s", (test_supervisor,))
            mv_count = cursor.fetchone()[0]
            
            # åŸå§‹æŸ¥è¯¢è®°å½•æ•°
            cursor.execute("""
                SELECT COUNT(*)
                FROM user_hierarchy h
                JOIN financial_funds f ON h.subordinate_id = f.handle_by
                WHERE h.user_id = %s
            """, (test_supervisor,))
            original_count = cursor.fetchone()[0]
            
            safe_print(f"  ç‰©åŒ–è§†å›¾: {mv_count:,} æ¡")
            safe_print(f"  åŸå§‹æŸ¥è¯¢: {original_count:,} æ¡")
            
            if mv_count == original_count:
                safe_print("  âœ… æ•°æ®ä¸€è‡´æ€§éªŒè¯é€šè¿‡")
            else:
                safe_print(f"  âŒ æ•°æ®ä¸ä¸€è‡´ï¼Œå·®å¼‚: {abs(mv_count - original_count):,} æ¡")
        
        return total_records > 0
        
    except mysql.connector.Error as e:
        safe_print(f"âŒ éªŒè¯å¤±è´¥: {e}")
        return False
    finally:
        cursor.close()
        conn.close()

def main():
    parser = argparse.ArgumentParser(description="ç‰©åŒ–è§†å›¾åˆå§‹åŒ–æ€§èƒ½ä¼˜åŒ–")
    parser.add_argument("--batch_size", type=int, default=100, help="æ¯æ‰¹å¤„ç†çš„supervisoræ•°é‡")
    parser.add_argument("--max_workers", type=int, default=4, help="å¹¶è¡Œçº¿ç¨‹æ•°")
    parser.add_argument("--skip_backup", action="store_true", help="è·³è¿‡è¡¨å¤‡ä»½å’Œé‡å»º")
    parser.add_argument("--only_indexes", action="store_true", help="åªåˆ›å»ºç´¢å¼•")
    parser.add_argument("--verify_only", action="store_true", help="åªè¿›è¡ŒéªŒè¯")
    
    args = parser.parse_args()
    
    overall_start_time = time.time()
    
    safe_print("ğŸš€ ç‰©åŒ–è§†å›¾åˆå§‹åŒ–æ€§èƒ½ä¼˜åŒ–")
    safe_print(f"æ‰¹æ¬¡å¤§å°: {args.batch_size} supervisor/æ‰¹æ¬¡")
    safe_print(f"å¹¶è¡Œçº¿ç¨‹: {args.max_workers}")
    
    if args.verify_only:
        verify_materialized_view()
        return
    
    if args.only_indexes:
        create_indexes_after_data_load()
        return
    
    success = True
    
    # 1. ä¼˜åŒ–MySQLè®¾ç½®
    if not optimize_mysql_settings():
        safe_print("MySQLä¼˜åŒ–å¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œ")
    
    # 2. é‡å»ºè¡¨ç»“æ„ï¼ˆé™¤éè·³è¿‡ï¼‰
    if not args.skip_backup:
        if not backup_and_recreate_mv_table():
            safe_print("è¡¨ç»“æ„é‡å»ºå¤±è´¥ï¼Œé€€å‡º")
            return
    
    # 3. å¹¶è¡Œå¡«å……æ•°æ®
    if not parallel_populate_materialized_view(args.max_workers, args.batch_size):
        safe_print("æ•°æ®å¡«å……å¤±è´¥")
        success = False
    
    # 4. åˆ›å»ºç´¢å¼•
    if success:
        if not create_indexes_after_data_load():
            safe_print("ç´¢å¼•åˆ›å»ºå¤±è´¥")
            success = False
    
    # 5. æ›´æ–°æ—¶é—´æˆ³
    if success:
        if not update_timestamps():
            safe_print("æ—¶é—´æˆ³æ›´æ–°å¤±è´¥")
    
    # 6. æ¢å¤MySQLè®¾ç½®
    restore_mysql_settings()
    
    # 7. éªŒè¯ç»“æœ
    if success:
        verify_materialized_view()
    
    overall_elapsed_time = time.time() - overall_start_time
    
    safe_print(f"\n{'='*60}")
    if success:
        safe_print("ğŸ‰ ç‰©åŒ–è§†å›¾ä¼˜åŒ–åˆå§‹åŒ–å®Œæˆï¼")
    else:
        safe_print("âŒ ç‰©åŒ–è§†å›¾åˆå§‹åŒ–è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯")
    
    safe_print(f"æ€»è€—æ—¶: {overall_elapsed_time:.2f} ç§’ ({overall_elapsed_time/60:.1f} åˆ†é’Ÿ)")
    safe_print(f"{'='*60}")
    
    if success:
        safe_print("\nä¼˜åŒ–æ•ˆæœï¼š")
        safe_print("âœ… æ‰¹é‡å¤„ç†å‡å°‘æ•°æ®åº“é”ç«äº‰")
        safe_print("âœ… å¹¶è¡Œå¤„ç†æå‡æ•´ä½“é€Ÿåº¦")
        safe_print("âœ… å»¶è¿Ÿç´¢å¼•åˆ›å»ºå‡å°‘æ’å…¥å¼€é”€")
        safe_print("âœ… MySQLä¼˜åŒ–é…ç½®æå‡æ€§èƒ½")
        
        estimated_improvement = 1.5 * 60 * 60 / overall_elapsed_time  # ç›¸å¯¹äº1.5å°æ—¶çš„æå‡å€æ•°
        safe_print(f"\né¢„è®¡æ€§èƒ½æå‡: {estimated_improvement:.1f}x")

if __name__ == "__main__":
    main()

